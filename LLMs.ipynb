{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7354003,"sourceType":"datasetVersion","datasetId":4270967}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom prettytable import PrettyTable\n\n# Load your dataset\ndf = pd.read_csv('/kaggle/input/llms-details/llm.csv')\n\n# Preprocessing\ndf['name'] = df['name'].str.lower()\ndf['owner'] = df['owner'].str.lower()\n\n# TF-IDF Vectorization\nvectorizer = TfidfVectorizer()\nname_vectors = vectorizer.fit_transform(df['name'])\n\ndef get_model_details(user_input):\n    # Preprocess user input\n    user_input = user_input.lower()\n    \n    # Vectorize user input\n    user_vector = vectorizer.transform([user_input])\n    \n    # Calculate cosine similarity\n    similarities = cosine_similarity(user_vector, name_vectors).flatten()\n    \n    # Find the index of the most similar model\n    most_similar_index = similarities.argmax()\n    \n    # Get the details of the most similar model\n    model_details = df.iloc[most_similar_index]\n    \n    return model_details\n\n# Example usage:\nuser_input = input(\"Enter Model Name to see the details: \")\nresult = get_model_details(user_input)\n\n# Print the result in a table\ntable = PrettyTable()\ntable.field_names = [\"Model LLM\", \"Owner\", \"Train on x billion parameters\", \"Date of Release\"]\ntable.add_row([result['name'], result['owner'], result['trained on x billion parameters'], result['date']])\nprint(\"\\nModel Details:\")\nprint(table)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-07T07:07:00.506896Z","iopub.execute_input":"2024-01-07T07:07:00.507266Z","iopub.status.idle":"2024-01-07T07:07:06.699769Z","shell.execute_reply.started":"2024-01-07T07:07:00.507238Z","shell.execute_reply":"2024-01-07T07:07:06.699090Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter Model Name to see the details:  t5\n"},{"name":"stdout","text":"\nModel Details:\n+-----------+--------+-------------------------------+-----------------+\n| Model LLM | Owner  | Train on x billion parameters | Date of Release |\n+-----------+--------+-------------------------------+-----------------+\n|     t5    | google |              11.0             |      Oct-19     |\n+-----------+--------+-------------------------------+-----------------+\n","output_type":"stream"}]}]}